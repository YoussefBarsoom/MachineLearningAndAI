{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Homework_04YoussefBarsoom.ipynb","provenance":[],"collapsed_sections":[]},"coursera":{"course_slug":"neural-networks-deep-learning","graded_item_id":"XaIWT","launcher_item_id":"zAgPl"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1LwvvMtG18SK"},"source":["# Recurrent Neural Network Homework\n","\n","This is the 4th assignment for CAP 4630 and we will implement a basic RNN network and an LSTM network with Keras to solve two problems. \\\n","You will use **\"Tasks\"** and **\"Hints\"** to finish the work. **(Total 100 points, including 15 bonus points)** \\\n","You may use Machine Learning libaries like Scikit-learn for data preprocessing.\n","\n","**Task Overview:**\n","- Implement a basic RNN network to solve time series prediction \n","- Implement an LSTM network to conduct sentiment analysis"]},{"cell_type":"markdown","metadata":{"id":"l24oSrIK18SL"},"source":["## 1 - Implement Basic RNN network with Keras to predict time series##\n","### 1.1 Prepare the data (17 Points)\n","\n","Prepare time series data for deep neural network training.\\\n","\n","**Tasks:**\n","1. Load the given train and test data: \"train.txt\" and \"test.txt\". **(5 Points)**\n","2. Generate the **TRAIN** and **TEST** labels. **(5 Points)**\n","3. Normalize the **TRAIN** and **TEST** data with sklearn function \"MinMaxScaler\". **(5 Points)**\n","4. **PRINT OUT** the **TEST** data and label. **(2 Points)**\n","\n","**Hints:**  \n","1. The length of original train data is 113 which starts from **\"1949-01\"** to **\"1958-05\"**. The length of original test data is 29, which starts from **\"1958-07\"** to **\"1960-11\"**. \n","2. Set the data types of both train and test data to \"float32\". \n","3. When you prepared input data X (sequences) and oupt data Y (labels), please consider the following relationship:\n","    - The sequence X should be the **past 12** datapoints in the time series, i.e., observation sequence with historical window of 12. You may check the time series data and think about the reason.\n","    - The label Y should be the **next 1** datapoint in the time series (one point ahead prediction).\n","4. The first 3 **TRAIN** data and label should be:\n","\n","- trainX[0] = [[0.02203858 &nbsp; 0.03856748 &nbsp; 0.077135 &nbsp;  0.06887051 &nbsp; 0.04683197 &nbsp; 0.08539945 &nbsp; 0.12121212 &nbsp; 0.12121212 &nbsp; 0.08815429 &nbsp; 0.04132232 &nbsp; 0.    &nbsp; 0.03856748]]\n","- trainY[0] = [0.03030303]\n","\n","- trianX[1] = [[0.03856748 &nbsp; 0.077135 &nbsp;  0.06887051 &nbsp; 0.04683197  &nbsp; 0.08539945  &nbsp; 0.12121212  &nbsp; 0.12121212  &nbsp; 0.08815429  &nbsp; 0.04132232  &nbsp; 0.     &nbsp;  0.03856748   &nbsp; 0.03030303]]\n","- trainY[1] = [0.06060606]\n","\n","- trainX[2] =  [[0.077135 &nbsp;  0.06887051 &nbsp; 0.04683197 &nbsp; 0.08539945 &nbsp; 0.12121212 &nbsp; 0.12121212 &nbsp; 0.08815429 &nbsp; 0.04132232 &nbsp; 0.    &nbsp;     0.03856748 &nbsp; 0.03030303 &nbsp; 0.06060606]]\n","- trainY[2] = [0.10192838]\n","\n","5. Apply the MinMaxScaler to both the train and test data.\\\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n","\n","\n","6. After the preparation with scaler fitting, the shapes of trainX, trainY, testX, and testY are as follows:\\\n","trainX.shape = (101, 1, 12)\\\n","trainY.shape = (101,)\\\n","testX.shape = (17, 1, 12)\\\n","testY.shape = (17,)"]},{"cell_type":"code","metadata":{"id":"hS7xhrC3-_-1","executionInfo":{"status":"ok","timestamp":1637381599290,"user_tz":-120,"elapsed":3167,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}}},"source":["### Import Libraries ###\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import tensorflow.keras.layers \n","import random\n","import numpy as np\n","\n","### Set random seed to ensure deterministic results\n","import os\n","seed_value = 1\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","def reset_random_seeds():\n","  tf.random.set_seed(seed_value)\n","  np.random.seed(seed_value)\n","  random.seed(seed_value)\n","reset_random_seeds()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"shAj2Y6IuxUv","executionInfo":{"status":"ok","timestamp":1637381604543,"user_tz":-120,"elapsed":2157,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}}},"source":["### Prepare and Preprocess Data Here ###\n","from pandas import read_csv\n","\n","### Design a Function to Prepare Observation Sequences and Corresponding Labels ###\n","\n","def create_dataset(dataset, look_back=12): # look_back is used to specify input sequence length\n","  dataX, dataY = [], []\n","  for i in range(len(dataset)-look_back):\n","    dataX.append(dataset[i:i+look_back]) \n","    dataY.append(dataset[i+look_back]) \n","\n","  return np.array(dataX), np.array(dataY)\n","\n","\n","### Train and Test Data Loading with float32 type ####\n","dataframe_train = read_csv('train.txt', usecols=[1], engine='python') # Read train.txt \n","dataset_train = dataframe_train.values\n","dataset_train = dataset_train.astype('float32') # Specify the data type to 'float32'\n","dataframe_test = read_csv('test.txt', usecols=[1], engine='python') # Read train.txt \n","dataset_test = dataframe_test.values\n","dataset_test = dataset_test.astype('float32') # Specify the data type to 'float32'\n","\n","\n","\n","### Scale Training and Test Data to [0, 1] ###\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler(feature_range=(0, 1)) # specify the scaler\n","train = scaler.fit_transform(dataset_train) # fit the scaler to the training data\n","test = scaler.transform(dataset_test) # fit the scaler to the test data\n","\n","### Training and Test Data Split ###\n","trainX, trainY = create_dataset(train, look_back=12)\n","testX, testY =  create_dataset(test, look_back=12)\n","\n","### Training and Test Data Reshape (to fit RNN input) ###\n","trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n","testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQ1uHWzX8wlH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637382919385,"user_tz":-120,"elapsed":13,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"b8f3bf7d-21d3-4de8-d6bf-1bd674b14eb0"},"source":["### Print Out the TEST Data and Labels Here ###\n","print(testX)\n","print(testY)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[1.0661157  1.1046832  0.8264463  0.70247936 0.5674931  0.64187324\n","   0.70523417 0.6556474  0.8319559  0.8044077  0.87052345 1.013774  ]]\n","\n"," [[1.1046832  0.8264463  0.70247936 0.5674931  0.64187324 0.70523417\n","   0.6556474  0.8319559  0.8044077  0.87052345 1.013774   1.2231405 ]]\n","\n"," [[0.8264463  0.70247936 0.5674931  0.64187324 0.70523417 0.6556474\n","   0.8319559  0.8044077  0.87052345 1.013774   1.2231405  1.2534435 ]]\n","\n"," [[0.70247936 0.5674931  0.64187324 0.70523417 0.6556474  0.8319559\n","   0.8044077  0.87052345 1.013774   1.2231405  1.2534435  0.98898065]]\n","\n"," [[0.5674931  0.64187324 0.70523417 0.6556474  0.8319559  0.8044077\n","   0.87052345 1.013774   1.2231405  1.2534435  0.98898065 0.8347107 ]]\n","\n"," [[0.64187324 0.70523417 0.6556474  0.8319559  0.8044077  0.87052345\n","   1.013774   1.2231405  1.2534435  0.98898065 0.8347107  0.7107438 ]]\n","\n"," [[0.70523417 0.6556474  0.8319559  0.8044077  0.87052345 1.013774\n","   1.2231405  1.2534435  0.98898065 0.8347107  0.7107438  0.8292011 ]]\n","\n"," [[0.6556474  0.8319559  0.8044077  0.87052345 1.013774   1.2231405\n","   1.2534435  0.98898065 0.8347107  0.7107438  0.8292011  0.8622589 ]]\n","\n"," [[0.8319559  0.8044077  0.87052345 1.013774   1.2231405  1.2534435\n","   0.98898065 0.8347107  0.7107438  0.8292011  0.8622589  0.79063356]]\n","\n"," [[0.8044077  0.87052345 1.013774   1.2231405  1.2534435  0.98898065\n","   0.8347107  0.7107438  0.8292011  0.8622589  0.79063356 0.8677685 ]]\n","\n"," [[0.87052345 1.013774   1.2231405  1.2534435  0.98898065 0.8347107\n","   0.7107438  0.8292011  0.8622589  0.79063356 0.8677685  0.98347104]]\n","\n"," [[1.013774   1.2231405  1.2534435  0.98898065 0.8347107  0.7107438\n","   0.8292011  0.8622589  0.79063356 0.8677685  0.98347104 1.013774  ]]\n","\n"," [[1.2231405  1.2534435  0.98898065 0.8347107  0.7107438  0.8292011\n","   0.8622589  0.79063356 0.8677685  0.98347104 1.013774   1.1873279 ]]\n","\n"," [[1.2534435  0.98898065 0.8347107  0.7107438  0.8292011  0.8622589\n","   0.79063356 0.8677685  0.98347104 1.013774   1.1873279  1.4269972 ]]\n","\n"," [[0.98898065 0.8347107  0.7107438  0.8292011  0.8622589  0.79063356\n","   0.8677685  0.98347104 1.013774   1.1873279  1.4269972  1.3829201 ]]\n","\n"," [[0.8347107  0.7107438  0.8292011  0.8622589  0.79063356 0.8677685\n","   0.98347104 1.013774   1.1873279  1.4269972  1.3829201  1.1129477 ]]\n","\n"," [[0.7107438  0.8292011  0.8622589  0.79063356 0.8677685  0.98347104\n","   1.013774   1.1873279  1.4269972  1.3829201  1.1129477  0.98347104]]]\n","[[548.     ]\n"," [559.     ]\n"," [462.99997]\n"," [407.     ]\n"," [362.     ]\n"," [405.     ]\n"," [417.     ]\n"," [391.     ]\n"," [418.99997]\n"," [461.     ]\n"," [471.99997]\n"," [535.     ]\n"," [622.     ]\n"," [606.     ]\n"," [508.00003]\n"," [461.     ]\n"," [390.     ]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"0AlakqA_vuFb"},"source":["### 1.2 - Build the RNN model (20 Points) ##\n","\n","\n","Build an RNN model with SimpleRNN cell. \n","\n","**Tasks:**\n","1. Build an RNN model with 1 simple RNN layer and 1 Dense layer.  **(10 Points)**\n","2. Compile the model. **(5 Points)**\n","3. Train the model for **1000** epochs with **batch_size = 10**. **(5 Points)**\n","\n","**Hints:**  \n","1. You may consider **tensorflow.keras.layers.SimpleRNN(unit_size=4)** to specify RNN cells.\n","2. Use loss function = 'mean_squared_error' and select **Adam** optimizer with **learning_rate=0.005** and other default settings.\n","3. After first epoch, the train loss is changed to around **0.0912**. \n","4. The model summary is as follows:\n","- Total params: 73\n","- Trainable params: 73\n","- Non-trainable params: 0"]},{"cell_type":"code","metadata":{"id":"Jn92qh8oyq0B","executionInfo":{"status":"ok","timestamp":1637381614980,"user_tz":-120,"elapsed":1827,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}}},"source":["### Build the RNN Model ###\n","import keras\n","from keras.models import Sequential\n","\n","keras.backend.clear_session()\n","\n","model = Sequential() # Declare Sequential class and assign it to variable \"model\"\n","model.add(tf.keras.layers.SimpleRNN(units=4)) # Add a simple RNN layer with unit_size=4 in the model \n","model.add(keras.layers.Dense(units=1)) # Add a following Dense layer with units=1 in the model "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnO-5WT-3hgH","executionInfo":{"status":"ok","timestamp":1637381617390,"user_tz":-120,"elapsed":4,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}}},"source":["### Compile the RNN Model  ###\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n","model.compile(loss='mean_squared_error',optimizer=opt) # model compiled with mean_squared_error loss and adam optimizer"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tpZAutlzify","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637381706961,"user_tz":-120,"elapsed":83445,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"73b5f906-1e34-424e-a26f-ea9b5055809c"},"source":["### Train the RNN Model  ###\n","\n","model.fit(trainX,trainY,epochs=1000, batch_size=10) # model fit with epoch=1000, batch_size=10; verbose=2 is optional.\n","model.summary() # print out model structure with model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","11/11 [==============================] - 1s 6ms/step - loss: 0.0912\n","Epoch 2/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0327\n","Epoch 3/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0244\n","Epoch 4/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0217\n","Epoch 5/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0187\n","Epoch 6/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0161\n","Epoch 7/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0150\n","Epoch 8/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0135\n","Epoch 9/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0121\n","Epoch 10/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0109\n","Epoch 11/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0099\n","Epoch 12/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0094\n","Epoch 13/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0091\n","Epoch 14/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0079\n","Epoch 15/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0064\n","Epoch 16/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0068\n","Epoch 17/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0056\n","Epoch 18/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0049\n","Epoch 19/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0050\n","Epoch 20/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0042\n","Epoch 21/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0041\n","Epoch 22/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0037\n","Epoch 23/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0037\n","Epoch 24/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0034\n","Epoch 25/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0032\n","Epoch 26/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0030\n","Epoch 27/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0033\n","Epoch 28/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0027\n","Epoch 29/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0026\n","Epoch 30/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0024\n","Epoch 31/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0024\n","Epoch 32/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0023\n","Epoch 33/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0023\n","Epoch 34/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0022\n","Epoch 35/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0021\n","Epoch 36/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0022\n","Epoch 37/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0022\n","Epoch 38/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0023\n","Epoch 39/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 40/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 41/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0019\n","Epoch 42/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 43/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0018\n","Epoch 44/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0019\n","Epoch 45/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0021\n","Epoch 46/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 47/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 48/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 49/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0018\n","Epoch 50/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 51/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0018\n","Epoch 52/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0017\n","Epoch 53/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 54/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 55/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0015\n","Epoch 56/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 57/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 58/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 59/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0017\n","Epoch 60/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 61/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0015\n","Epoch 62/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 63/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 64/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0016\n","Epoch 65/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0015\n","Epoch 66/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 67/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 68/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 69/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 70/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0015\n","Epoch 71/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 72/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 73/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 74/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 75/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 76/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0013\n","Epoch 77/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 78/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0016\n","Epoch 79/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 80/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 81/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 82/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 83/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 84/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0022\n","Epoch 85/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0014\n","Epoch 86/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 87/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 88/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 89/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 90/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 91/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 92/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 93/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 94/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 95/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 96/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 97/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 98/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 99/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 100/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 101/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 102/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 103/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 104/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 105/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0012\n","Epoch 106/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 107/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 108/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 109/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 110/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0013\n","Epoch 111/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 112/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0013\n","Epoch 113/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 114/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0011\n","Epoch 115/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 116/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0011\n","Epoch 117/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 118/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 119/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 120/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 121/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 122/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0014\n","Epoch 123/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0012\n","Epoch 124/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 125/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0014\n","Epoch 126/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 127/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 128/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 129/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0021\n","Epoch 130/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 131/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 132/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 133/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 134/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 135/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 136/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 137/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 138/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 139/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 140/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 141/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 142/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 143/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 144/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 145/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 146/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 147/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 148/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 149/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 150/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 151/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 152/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 153/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 154/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 155/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 156/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 157/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 158/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 159/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 160/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 161/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 162/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0025\n","Epoch 163/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0017\n","Epoch 164/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 165/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 166/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 167/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 168/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 169/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 170/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 171/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 172/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 173/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 174/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 175/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 176/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 177/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 178/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0020\n","Epoch 179/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 180/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 181/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 182/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0018\n","Epoch 183/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 184/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 185/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 186/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 187/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 188/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 189/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 190/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0018\n","Epoch 191/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 192/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 193/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 194/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 195/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 196/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 197/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 198/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 199/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0011\n","Epoch 200/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 201/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 202/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 203/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 204/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 205/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 206/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 207/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 208/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 209/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 210/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 211/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 212/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 213/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 214/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 215/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 216/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 217/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 218/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 219/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 220/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 221/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 222/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 223/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 224/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 225/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 226/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 227/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0010\n","Epoch 228/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 229/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 230/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 231/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 232/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 233/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0011\n","Epoch 234/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 235/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 236/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 237/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0014\n","Epoch 238/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 239/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0014\n","Epoch 240/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 241/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0012\n","Epoch 242/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 243/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 244/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 245/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 246/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 247/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 248/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0013\n","Epoch 249/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 250/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 251/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 252/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 253/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 254/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 255/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 256/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 257/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 258/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 259/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 260/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 261/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 262/1000\n","11/11 [==============================] - 0s 4ms/step - loss: 0.0012\n","Epoch 263/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 264/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 265/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 266/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 267/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 268/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 269/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 270/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 271/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 272/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 273/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 274/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 275/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 276/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 277/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 278/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 279/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.9795e-04\n","Epoch 280/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 281/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 282/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 283/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 284/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0018\n","Epoch 285/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0022\n","Epoch 286/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 287/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0021\n","Epoch 288/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0014\n","Epoch 289/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 290/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 291/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 292/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 293/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 294/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 295/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 296/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 297/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 298/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 299/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 300/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 301/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 302/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 303/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 304/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 305/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.9521e-04\n","Epoch 306/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 307/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 308/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 309/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 310/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 311/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 312/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 313/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 314/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 315/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 316/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 317/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 318/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 319/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 320/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 321/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0020\n","Epoch 322/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 323/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 324/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 325/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 326/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.9462e-04\n","Epoch 327/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 328/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8941e-04\n","Epoch 329/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 330/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 331/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 332/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 333/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 334/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 335/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 336/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 337/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 338/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0023\n","Epoch 339/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 340/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 341/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 342/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 343/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 344/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 345/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 346/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 347/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 348/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 349/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 350/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0022\n","Epoch 351/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 352/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 353/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 354/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 355/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8242e-04\n","Epoch 356/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 357/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 358/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 359/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 360/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 361/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 362/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 363/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 364/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 365/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 366/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 367/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 368/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 369/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 370/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 371/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 372/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 373/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 374/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 375/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 376/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 377/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 378/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 379/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 380/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 381/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 382/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 383/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 384/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 385/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 386/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 387/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 388/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7419e-04\n","Epoch 389/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2529e-04\n","Epoch 390/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 391/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9533e-04\n","Epoch 392/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8371e-04\n","Epoch 393/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 394/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9053e-04\n","Epoch 395/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 396/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.1045e-04\n","Epoch 397/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 398/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 399/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 400/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 401/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 402/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 403/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9788e-04\n","Epoch 404/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 405/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 406/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 407/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 408/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 409/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9670e-04\n","Epoch 410/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 411/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 412/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 413/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 414/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9376e-04\n","Epoch 415/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 416/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 417/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0026\n","Epoch 418/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 419/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9380e-04\n","Epoch 420/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 421/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3959e-04\n","Epoch 422/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5620e-04\n","Epoch 423/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 424/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6653e-04\n","Epoch 425/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 426/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 427/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 428/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8244e-04\n","Epoch 429/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 430/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 431/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8211e-04\n","Epoch 432/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 433/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 434/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 435/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 436/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 437/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 438/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 439/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 440/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 441/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.7004e-04\n","Epoch 442/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 443/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 444/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 445/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 446/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 447/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8024e-04\n","Epoch 448/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 449/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 450/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 451/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8794e-04\n","Epoch 452/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 453/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 454/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 455/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 456/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 457/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 458/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 459/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 460/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 461/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 462/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 463/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 464/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8389e-04\n","Epoch 465/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 466/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 467/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6645e-04\n","Epoch 468/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 469/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 470/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 471/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 472/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 473/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3619e-04\n","Epoch 474/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 475/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8259e-04\n","Epoch 476/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.5914e-04\n","Epoch 477/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 478/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 479/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 480/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 481/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 482/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 483/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 484/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.9722e-04\n","Epoch 485/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.8557e-04\n","Epoch 486/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 487/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 488/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 489/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 490/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 491/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 492/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 493/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.4238e-04\n","Epoch 494/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6272e-04\n","Epoch 495/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 496/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 497/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6377e-04\n","Epoch 498/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 499/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 500/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 501/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 502/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 503/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 504/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 505/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 506/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 507/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 508/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 509/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 510/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 511/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 512/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 513/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.9369e-04\n","Epoch 514/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 515/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 516/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5918e-04\n","Epoch 517/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 518/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 519/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 520/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 521/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7707e-04\n","Epoch 522/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0014\n","Epoch 523/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 524/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 525/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 526/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7694e-04\n","Epoch 527/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7724e-04\n","Epoch 528/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 529/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 530/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 531/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 532/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 533/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 534/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 535/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 536/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 537/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6898e-04\n","Epoch 538/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5523e-04\n","Epoch 539/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 540/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 541/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 542/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0020\n","Epoch 543/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0014\n","Epoch 544/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 545/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 546/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5089e-04\n","Epoch 547/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 548/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 549/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 550/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 551/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8743e-04\n","Epoch 552/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.7206e-04\n","Epoch 553/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.3641e-04\n","Epoch 554/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.3167e-04\n","Epoch 555/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6354e-04\n","Epoch 556/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4272e-04\n","Epoch 557/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 558/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 559/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5244e-04\n","Epoch 560/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 561/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 562/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 563/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 564/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 565/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 566/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 567/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7856e-04\n","Epoch 568/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 569/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 570/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 571/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3978e-04\n","Epoch 572/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 573/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 574/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 575/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4621e-04\n","Epoch 576/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 577/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.3433e-04\n","Epoch 578/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 579/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.5482e-04\n","Epoch 580/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6368e-04\n","Epoch 581/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4307e-04\n","Epoch 582/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.1832e-04\n","Epoch 583/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2698e-04\n","Epoch 584/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4165e-04\n","Epoch 585/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 586/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.1764e-04\n","Epoch 587/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.1415e-04\n","Epoch 588/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 589/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 590/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 591/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.4759e-04\n","Epoch 592/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3249e-04\n","Epoch 593/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2430e-04\n","Epoch 594/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.0578e-04\n","Epoch 595/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8084e-04\n","Epoch 596/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 597/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 598/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.0680e-04\n","Epoch 599/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5429e-04\n","Epoch 600/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 601/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 602/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 603/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 604/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 605/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 606/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 607/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 608/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 609/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 610/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 611/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8687e-04\n","Epoch 612/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 613/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.6889e-04\n","Epoch 614/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 615/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 616/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 617/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0019\n","Epoch 618/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 619/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6772e-04\n","Epoch 620/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.0478e-04\n","Epoch 621/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 622/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 623/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 624/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0016\n","Epoch 625/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 626/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.5418e-04\n","Epoch 627/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 628/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 629/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 630/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.6097e-04\n","Epoch 631/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 632/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3775e-04\n","Epoch 633/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 634/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 635/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 636/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 637/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 638/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 639/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 640/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 641/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 642/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9440e-04\n","Epoch 643/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 644/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 645/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7898e-04\n","Epoch 646/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 647/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.3652e-04\n","Epoch 648/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.0563e-04\n","Epoch 649/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 650/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 651/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 652/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5862e-04\n","Epoch 653/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 654/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 655/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 656/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0014\n","Epoch 657/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 658/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 659/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.9746e-04\n","Epoch 660/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6095e-04\n","Epoch 661/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 662/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 663/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 664/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 665/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 666/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2263e-04\n","Epoch 667/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.7650e-04\n","Epoch 668/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 669/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.4411e-04\n","Epoch 670/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.5821e-04\n","Epoch 671/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3528e-04\n","Epoch 672/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 673/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 674/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6332e-04\n","Epoch 675/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 676/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 677/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 678/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 679/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2020e-04\n","Epoch 680/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7106e-04\n","Epoch 681/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.0783e-04\n","Epoch 682/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 683/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 684/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4498e-04\n","Epoch 685/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2000e-04\n","Epoch 686/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 687/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.0296e-04\n","Epoch 688/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 689/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 690/1000\n","11/11 [==============================] - 0s 9ms/step - loss: 0.0015\n","Epoch 691/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 692/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.2431e-04\n","Epoch 693/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3703e-04\n","Epoch 694/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0015\n","Epoch 695/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 696/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.1653e-04\n","Epoch 697/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 698/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0017\n","Epoch 699/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0018\n","Epoch 700/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 701/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3547e-04\n","Epoch 702/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3749e-04\n","Epoch 703/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.3421e-04\n","Epoch 704/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 705/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2658e-04\n","Epoch 706/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6446e-04\n","Epoch 707/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.5140e-04\n","Epoch 708/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 709/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 710/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7304e-04\n","Epoch 711/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 712/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 713/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0019\n","Epoch 714/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 715/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 716/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 717/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.1730e-04\n","Epoch 718/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8097e-04\n","Epoch 719/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 720/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 721/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6969e-04\n","Epoch 722/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9137e-04\n","Epoch 723/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3814e-04\n","Epoch 724/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9854e-04\n","Epoch 725/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3446e-04\n","Epoch 726/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.1668e-04\n","Epoch 727/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.6288e-04\n","Epoch 728/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 729/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.2304e-04\n","Epoch 730/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 731/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 732/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 733/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 734/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 735/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 736/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9700e-04\n","Epoch 737/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.1317e-04\n","Epoch 738/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.8475e-04\n","Epoch 739/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 740/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9473e-04\n","Epoch 741/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4741e-04\n","Epoch 742/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 743/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.2328e-04\n","Epoch 744/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 745/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.5956e-04\n","Epoch 746/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3668e-04\n","Epoch 747/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7676e-04\n","Epoch 748/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 9.1377e-04\n","Epoch 749/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 750/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.0064e-04\n","Epoch 751/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.6764e-04\n","Epoch 752/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.0453e-04\n","Epoch 753/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.0848e-04\n","Epoch 754/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.5179e-04\n","Epoch 755/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6001e-04\n","Epoch 756/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.7292e-04\n","Epoch 757/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.4919e-04\n","Epoch 758/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.5156e-04\n","Epoch 759/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.7575e-04\n","Epoch 760/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 761/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0012\n","Epoch 762/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0017\n","Epoch 763/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 764/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8885e-04\n","Epoch 765/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.2751e-04\n","Epoch 766/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.6893e-04\n","Epoch 767/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2973e-04\n","Epoch 768/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.9363e-04\n","Epoch 769/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 770/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.8312e-04\n","Epoch 771/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.8981e-04\n","Epoch 772/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.7803e-04\n","Epoch 773/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 774/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 775/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.4623e-04\n","Epoch 776/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9256e-04\n","Epoch 777/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 778/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.4929e-04\n","Epoch 779/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 780/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.8061e-04\n","Epoch 781/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4991e-04\n","Epoch 782/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.9762e-04\n","Epoch 783/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 784/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2383e-04\n","Epoch 785/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.8179e-04\n","Epoch 786/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.4265e-04\n","Epoch 787/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 9.6066e-04\n","Epoch 788/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9792e-04\n","Epoch 789/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9704e-04\n","Epoch 790/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.1721e-04\n","Epoch 791/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.5217e-04\n","Epoch 792/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.8541e-04\n","Epoch 793/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0017\n","Epoch 794/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8459e-04\n","Epoch 795/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4120e-04\n","Epoch 796/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 797/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3798e-04\n","Epoch 798/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.7960e-04\n","Epoch 799/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2545e-04\n","Epoch 800/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3232e-04\n","Epoch 801/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.7031e-04\n","Epoch 802/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 803/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 804/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 805/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.5510e-04\n","Epoch 806/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 807/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.9798e-04\n","Epoch 808/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.8846e-04\n","Epoch 809/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8786e-04\n","Epoch 810/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.3074e-04\n","Epoch 811/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.1297e-04\n","Epoch 812/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4288e-04\n","Epoch 813/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.7573e-04\n","Epoch 814/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 9.0646e-04\n","Epoch 815/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2554e-04\n","Epoch 816/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 817/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 818/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.1095e-04\n","Epoch 819/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3573e-04\n","Epoch 820/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.8481e-04\n","Epoch 821/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.1135e-04\n","Epoch 822/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 823/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.9972e-04\n","Epoch 824/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.4987e-04\n","Epoch 825/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 826/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 827/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0012\n","Epoch 828/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3251e-04\n","Epoch 829/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 830/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 831/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.4900e-04\n","Epoch 832/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0010\n","Epoch 833/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0010\n","Epoch 834/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.6549e-04\n","Epoch 835/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8952e-04\n","Epoch 836/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.1616e-04\n","Epoch 837/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.2364e-04\n","Epoch 838/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.7937e-04\n","Epoch 839/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0011\n","Epoch 840/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9258e-04\n","Epoch 841/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.0834e-04\n","Epoch 842/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 843/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.6737e-04\n","Epoch 844/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0017\n","Epoch 845/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 846/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 847/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 848/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 8.8412e-04\n","Epoch 849/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0023\n","Epoch 850/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0016\n","Epoch 851/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.8924e-04\n","Epoch 852/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 853/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.1904e-04\n","Epoch 854/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 855/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 856/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 857/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 858/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.2667e-04\n","Epoch 859/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 860/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3503e-04\n","Epoch 861/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 862/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0014\n","Epoch 863/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.7223e-04\n","Epoch 864/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 865/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3417e-04\n","Epoch 866/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0014\n","Epoch 867/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0013\n","Epoch 868/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 869/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.2335e-04\n","Epoch 870/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.8545e-04\n","Epoch 871/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 872/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 873/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.9762e-04\n","Epoch 874/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 875/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 876/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.7529e-04\n","Epoch 877/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0013\n","Epoch 878/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 879/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 880/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4518e-04\n","Epoch 881/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 882/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3829e-04\n","Epoch 883/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 884/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 885/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 886/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.9666e-04\n","Epoch 887/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.4273e-04\n","Epoch 888/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.0720e-04\n","Epoch 889/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9258e-04\n","Epoch 890/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0014\n","Epoch 891/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.6007e-04\n","Epoch 892/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4224e-04\n","Epoch 893/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.8660e-04\n","Epoch 894/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 895/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4342e-04\n","Epoch 896/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.6252e-04\n","Epoch 897/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.4838e-04\n","Epoch 898/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.5435e-04\n","Epoch 899/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.7011e-04\n","Epoch 900/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 901/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.5611e-04\n","Epoch 902/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.8912e-04\n","Epoch 903/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 8.8880e-04\n","Epoch 904/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.8833e-04\n","Epoch 905/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 906/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4413e-04\n","Epoch 907/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9654e-04\n","Epoch 908/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.2575e-04\n","Epoch 909/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.5864e-04\n","Epoch 910/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.5291e-04\n","Epoch 911/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 9.7606e-04\n","Epoch 912/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 913/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 914/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0015\n","Epoch 915/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 916/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 917/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 918/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4584e-04\n","Epoch 919/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 920/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 921/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.6971e-04\n","Epoch 922/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 923/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4191e-04\n","Epoch 924/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 925/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9370e-04\n","Epoch 926/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.7017e-04\n","Epoch 927/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.5532e-04\n","Epoch 928/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.5969e-04\n","Epoch 929/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.4140e-04\n","Epoch 930/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0015\n","Epoch 931/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 932/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 933/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.3619e-04\n","Epoch 934/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.1453e-04\n","Epoch 935/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.3515e-04\n","Epoch 936/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8341e-04\n","Epoch 937/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 938/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 939/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.8184e-04\n","Epoch 940/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 941/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.9491e-04\n","Epoch 942/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.9920e-04\n","Epoch 943/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 944/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.8882e-04\n","Epoch 945/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4684e-04\n","Epoch 946/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.2971e-04\n","Epoch 947/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 948/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.7161e-04\n","Epoch 949/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.5840e-04\n","Epoch 950/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9879e-04\n","Epoch 951/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.8347e-04\n","Epoch 952/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0012\n","Epoch 953/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.0190e-04\n","Epoch 954/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.5813e-04\n","Epoch 955/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 956/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.8817e-04\n","Epoch 957/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.1011e-04\n","Epoch 958/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.7515e-04\n","Epoch 959/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 960/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 961/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.4826e-04\n","Epoch 962/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.2648e-04\n","Epoch 963/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 964/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8312e-04\n","Epoch 965/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.2092e-04\n","Epoch 966/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 9.0001e-04\n","Epoch 967/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9930e-04\n","Epoch 968/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.9156e-04\n","Epoch 969/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0012\n","Epoch 970/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.1734e-04\n","Epoch 971/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 972/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.2301e-04\n","Epoch 973/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.7140e-04\n","Epoch 974/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.1506e-04\n","Epoch 975/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0016\n","Epoch 976/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 977/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 0.0011\n","Epoch 978/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0010\n","Epoch 979/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0011\n","Epoch 980/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 9.9410e-04\n","Epoch 981/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.7088e-04\n","Epoch 982/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 983/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.3756e-04\n","Epoch 984/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.1370e-04\n","Epoch 985/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.3960e-04\n","Epoch 986/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.0568e-04\n","Epoch 987/1000\n","11/11 [==============================] - 0s 5ms/step - loss: 8.1513e-04\n","Epoch 988/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 9.8125e-04\n","Epoch 989/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 8.7202e-04\n","Epoch 990/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.4827e-04\n","Epoch 991/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.5968e-04\n","Epoch 992/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9087e-04\n","Epoch 993/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 994/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 0.0010\n","Epoch 995/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 9.4983e-04\n","Epoch 996/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0010\n","Epoch 997/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 0.0011\n","Epoch 998/1000\n","11/11 [==============================] - 0s 6ms/step - loss: 8.0722e-04\n","Epoch 999/1000\n","11/11 [==============================] - 0s 8ms/step - loss: 0.0010\n","Epoch 1000/1000\n","11/11 [==============================] - 0s 7ms/step - loss: 8.9368e-04\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," simple_rnn (SimpleRNN)      (None, 4)                 68        \n","                                                                 \n"," dense (Dense)               (None, 1)                 5         \n","                                                                 \n","=================================================================\n","Total params: 73\n","Trainable params: 73\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"Dd2jZl4n0H8m"},"source":["### 1.3 Evaluate Predictive Model Performance (10 Points)\n","\n","Predict datapoints with the observed datapoints and trained model. \n","\n","**Tasks:**\n","1. Do direct prediction on train and test datapoints with the obtained model in section 1.2. **(2 Points)**\n","2. Scale the prediction results back to original representation with the scaler.(scaler.inverse_transform function) **(3 Points)**\n","3. Calculate root mean squared error (RMSE) and **print out** the error for **both TRAIN and TEST**. **(3 Points)**\n","4. **Plot** the **TEST** label and prediction. **(2 Points)**\n","\n","\n","**Hints:**  \n","1. Scale back the predictions with the build-in function \"scaler.inverse_transform\".\\\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.inverse_transform\n","2. For validation: Train Score: **~10.92 RMSE** Test Score: **~27.70 RMSE**\n","3. The plot for validation is shown below (observation test data are blue and prediction results are orange):\n","\n","\n","![](https://drive.google.com/uc?export=view&id=10c1Fsa_9v0AQf2fDpCzGPFPxbIEso81u)\n"]},{"cell_type":"code","metadata":{"id":"KNEkAMxnz8Mq","executionInfo":{"status":"ok","timestamp":1637381729288,"user_tz":-120,"elapsed":1372,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}}},"source":["### Make Predictions ###\n","\n","trainPredict = model.predict(trainX)\n","testPredict = model.predict(testX)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbnRqEv9z-he","executionInfo":{"status":"ok","timestamp":1637381733089,"user_tz":-120,"elapsed":367,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}}},"source":["### Scale Back Predictions ###\n","\n","trainPredict = scaler.inverse_transform(trainPredict) # scale train prediction back with scaler.inverse_transform()\n","trainY = scaler.inverse_transform(trainY)  # scale train labels back with scaler.inverse_transform()\n","\n","testPredict = scaler.inverse_transform(testPredict) # scale test prediction back with scaler.inverse_transform()\n","testY = scaler.inverse_transform(testY) # scale test labels back with scaler.inverse_transform()\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdBWzmE91G6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637381738859,"user_tz":-120,"elapsed":416,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"97c674d1-3312-4a1e-f17f-178ff47dde7a"},"source":["### Calculate Root Mean Squared Error (RMSE) ###\n","import math\n","from sklearn.metrics import mean_squared_error # Import mean_squared_error from sklearn.metrics\n","trainScore = math.sqrt(mean_squared_error(trainY, trainPredict)) \n","testScore = math.sqrt(mean_squared_error(testY, testPredict))\n","print('Train Score: %.2f RMSE' % (trainScore))\n","print('Test Score: %.2f RMSE' % (testScore))\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Score: 10.92 RMSE\n","Test Score: 27.70 RMSE\n"]}]},{"cell_type":"code","metadata":{"id":"txdu8q7l1aju","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1637381743803,"user_tz":-120,"elapsed":1049,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"5a25da7b-29ed-47c8-c6f2-cdc6cae7b308"},"source":["### Plot Observation Data and Prediction Results with TEST dataset ###\n","\n","import matplotlib.pyplot as plt\n","plt.plot(testY) # Plot Observations in Test Set\n","plt.plot(testPredict) # Plot Predictions in Test Set\n","plt.show()\n"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"O49Ug-FhtCg8"},"source":["## 2 - Build an LSTM model to conduct sentiment analysis ##\n","\n","### 2.1 Prepare the data (13 Points) ###\n","\n","Prepare IMDB data for reccurent neural network training.\n","\n","**Tasks:**\n","1. Load the data from IMDB review dataset and **print out** the lengths of sequences. **(3 Points)**\n","2. Preprocess review data to meet the network input requirement by specifying **number of words=1000**, setting **the analysis length of the review = 100**, and **padding the input sequences**. **(10 Points)**\n","\n","**Hints:**  \n","1. You may load the IMDB data with keras.datasets.imdb.load_data(num_words=max_features). Here. max_features is set to **1000**.\n","2. You may use keras.preprocessing.sequence.pad_sequences(x_train, maxlen) to pad the input sequences and set maxlen to **100**.\n","\n","**Note:**\\\n","We train the built LSTM-based model with ALL training data; the **validation set** (aka **development set**) is set with the **testing set** for model evaluation. This split is common in the application with limited sampled observation data, like NLP problems.\n"]},{"cell_type":"code","metadata":{"id":"UI4ki461S2V3","executionInfo":{"status":"ok","timestamp":1637381752454,"user_tz":-120,"elapsed":366,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}}},"source":["import tensorflow as tf\n","import tensorflow.keras as keras\n","from keras import layers\n","import random\n","import numpy as np\n","\n","\n","### Set random seed to ensure deterministic results\n","import os\n","seed_value = 1\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","def reset_random_seeds():\n","  tf.random.set_seed(seed_value)\n","  np.random.seed(seed_value)\n","  random.seed(seed_value)\n","\n","reset_random_seeds() # randomly set initial data"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvV1Sv2a18SM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637381771914,"user_tz":-120,"elapsed":6056,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"dba31458-f264-463f-c1be-9a8056ea5443"},"source":["# Prepare the data here\n","\n","max_features = 1000 # Only consider the top 1k words\n","maxlen = 100 # Only consider the first 100 words of each movie review\n","\n","(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=max_features) # load IMDB data with specified num_words = 1000; testing set is set to validation set.\n","print(len(x_train), \"Training sequences\")\n","print(len(x_val), \"Validation sequences\")\n","x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen ) # Pad IMDB training data with specified maxlen=100\n","x_val = keras.preprocessing.sequence.pad_sequences(x_val,maxlen) # Pad IMDB validation data with specified maxlen=100\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["25000 Training sequences\n","25000 Validation sequences\n"]}]},{"cell_type":"markdown","metadata":{"id":"v_JFQeWK18SR"},"source":["### 2.2 - Design and train LSTM model (25 Points) ###\n","\n","Build an LSTM model.\n","\n","**Tasks:**\n","1. Build the LSTM model with **1 embedding layer**, **1 LSTM layer**, and **1 Dense layer**. **Print out** model summary. The embedding vector is specified with the dimension of **8**. **(10 Points)**\n","2. Compile the LSTM model with **Adam** optimizer, **binary_crossentropy** loss function, and **accuracy** metrics. **(5 Points)**  \n","3. Train the LSTM model with **batch_size=64 for 10 epochs** and report **training and validation accuracies over epochs**. **(5 Points)**\n","4. **Print out** best validation accuracy. **(5 Points)**\n","\n","\n","\n","**Hints:**  \n","1. Set input dimension to **1000** and output dimension to **8** for embedding layer.\n","2. Set **unit_size=8** for LSTM layer.\n","3. Set activation function to **sigmoid** for Dense layer.\n","4. For validation: the outputs for first epoch should be close to（but maybe not exactly following） the statistics below:\\\n","- **-loss: ~0.6402 - accuracy: ~0.6187 - val_loss: ~0.4645 - val_accuracy: ~0.7995**\n","5. The model summary is as follows:\n","- Total params: 8,553\n","- Trainable params: 8,553\n","- Non-trainable params: 0\n","\n","**Useful Reference:**\n","1. https://keras.io/examples/nlp/bidirectional_lstm_imdb/"]},{"cell_type":"code","metadata":{"id":"UDqqgFt118SS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637381894079,"user_tz":-120,"elapsed":111846,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"57dd6f2a-b714-4949-e7b9-60903498d6ea"},"source":["### Model design with Embedding and LSTM layers ####\n","inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n","x = layers.Embedding(input_dim=1000,output_dim=8)(inputs) # Embed data in an 8-dimensional vector\n","x = layers.LSTM(units=8)(x) # Add 1st layer of LSTM with 8 hidden states (aka units)\n","outputs = layers.Dense(1,activation=\"sigmoid\")(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n","\n","### Clear cached model to refresh memory and build new model for training ###\n","keras.backend.clear_session() # Clear cached model\n","model = keras.Model(inputs, outputs) # Build new keras model\n","model.summary() # Print out model summary\n","\n","model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"]) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n","#model.fit(x_train,y_train) # Train the compiled model with model.fit()\n","model.fit(x_train,y_train,epochs=10,batch_size=64,validation_data=(x_val,y_val)) # Train the compiled model with model.fit()"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, None, 8)           8000      \n","                                                                 \n"," lstm (LSTM)                 (None, 8)                 544       \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 8,553\n","Trainable params: 8,553\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 15s 33ms/step - loss: 0.5679 - accuracy: 0.7067 - val_loss: 0.4441 - val_accuracy: 0.8069\n","Epoch 2/10\n","391/391 [==============================] - 10s 26ms/step - loss: 0.4159 - accuracy: 0.8161 - val_loss: 0.4041 - val_accuracy: 0.8192\n","Epoch 3/10\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3833 - accuracy: 0.8329 - val_loss: 0.3851 - val_accuracy: 0.8267\n","Epoch 4/10\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3683 - accuracy: 0.8408 - val_loss: 0.3851 - val_accuracy: 0.8256\n","Epoch 5/10\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3627 - accuracy: 0.8437 - val_loss: 0.3809 - val_accuracy: 0.8291\n","Epoch 6/10\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3598 - accuracy: 0.8420 - val_loss: 0.4312 - val_accuracy: 0.8158\n","Epoch 7/10\n","391/391 [==============================] - 12s 32ms/step - loss: 0.3538 - accuracy: 0.8430 - val_loss: 0.3719 - val_accuracy: 0.8310\n","Epoch 8/10\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3469 - accuracy: 0.8470 - val_loss: 0.3735 - val_accuracy: 0.8310\n","Epoch 9/10\n","391/391 [==============================] - 10s 26ms/step - loss: 0.3410 - accuracy: 0.8488 - val_loss: 0.3893 - val_accuracy: 0.8314\n","Epoch 10/10\n","391/391 [==============================] - 12s 32ms/step - loss: 0.3359 - accuracy: 0.8522 - val_loss: 0.3818 - val_accuracy: 0.8299\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe189f55990>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"0vqvy2tdEw7J"},"source":["### 2.3 - LSTM hyperparameter tuning (Bonus 15 Points) ###\n","\n","Boost the performance of obtained LSTM (aka vanilla model) by hyperparameter tuning.\n","\n","**Tasks:**\n","Note: \n","- All modificiations are directly conducted based on the vanilla model above (from 2.2).\n","- For each scenario, **report <span style=\"color:red\"> BEST Validation Accuracy </span> and generate Training/Validation <span style=\"color:red\"> Accuracy plots over epochs</span>**. You may just paste the plot figures in the cells with **Markdown mode**, or leave the result after running. **Make sure it is already correctly shown in your submitted file.**\n","1.  Scenario 1 (**5 points**):\n","    - Add one additional LSTM layer (totally 2 LSTM layers).\n","    - Modify the embedding dimension to 16.\n","    - Modify the units of LSTM to 16.\n","2. Scenario 2 (**5 points**)\n","    - Add one additional LSTM layer (totally 2 LSTM layers).\n","    - Modify the embedding dimension to 128.\n","    - Modify the units of LSTM to 128.\n","3. Scenario 3 (**5 points**)\n","    - Add one additional LSTM layer (totally 2 LSTM layers).\n","    - Modify the embedding dimension to 128.\n","    - Modify the units of LSTM to 128.\n","    - Increase analysis length for review data to maxlen = 200\n","\n","**Hints:**  \n","For validation: the outputs for first epoch should be close to （but maybe not exactly following） the statistics below:\n","- Scenario 1: **loss: ~0.5839 - accuracy: ~0.6524 - val_loss: ~0.4079 - val_accuracy: ~0.8198**\n","- Scenario 2: **loss: ~0.5572 - accuracy: ~0.6911 - val_loss: ~0.3953 - val_accuracy: ~0.8244**\n","- Scenario 3: **loss: ~0.5605 - accuracy: ~0.6914 - val_loss: ~0.3402 - val_accuracy: ~0.8560**\n","\n","- Summary of Model 1: Total params: 20,241; Trainable params: 20,241; Non-trainable params: 0\n","- Summary of Model 2: Total params: 391,297; Trainable params: 391,297; Non-trainable params: 0\n","- Summary of Model 3: Total params: 391,297; Trainable params: 391,297; Non-trainable params: 0\n","\n","You may follow the example from the reference below to add additional LSTM layer.\n","\n","**Useful Reference:**\n","1. https://keras.io/examples/nlp/bidirectional_lstm_imdb/  \n"]},{"cell_type":"code","metadata":{"id":"6xMSM_GQt_P8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637382217813,"user_tz":-120,"elapsed":266683,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"3264033f-ee97-4b31-965f-5ab9d0c9886c"},"source":["########################### Scenario 1 ###########################\n","##################################################################\n","\n","### Set random seed to ensure deterministic results ###\n","import os\n","seed_value = 1\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","def reset_random_seeds():\n","   tf.random.set_seed(seed_value)\n","   np.random.seed(seed_value)\n","   random.seed(seed_value)\n","\n","reset_random_seeds() # randomly set initial data\n","\n","max_features = 1000 # Only consider the top 1k words\n","maxlen = 100 # Only consider the first 100 words of each movie review\n","\n","### Model design with Embedding and LSTM layers ####\n","inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n","x = layers.Embedding(input_dim=1000,output_dim=16)(inputs) # Embed data in a 16-dimensional vector\n","x = layers.LSTM(units=16,return_sequences='true' )(x) # Add 1st layer of LSTM with 16 hidden states (aka units); set return_sequences=true.\n","x = layers.LSTM(units=16 )(x) # Add 2nd layer of LSTM with 16 hidden states (aka units)\n","outputs = layers.Dense(units=1, activation=\"sigmoid\")(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n","\n","### Clear cached model to refresh memory and build new model for training ###\n","keras.backend.clear_session() # Clear cached model\n","model = keras.Model(inputs, outputs) # Build new keras model\n","model.summary() # Print out model summary\n","\n","model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"]) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n","model.fit(x_train,y_train,epochs=10,batch_size=64,validation_data=(x_val,y_val)) # Train the compiled model with model.fit()"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, None, 16)          16000     \n","                                                                 \n"," lstm (LSTM)                 (None, None, 16)          2112      \n","                                                                 \n"," lstm_1 (LSTM)               (None, 16)                2112      \n","                                                                 \n"," dense (Dense)               (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 20,241\n","Trainable params: 20,241\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 25s 54ms/step - loss: 0.4968 - accuracy: 0.7450 - val_loss: 0.4079 - val_accuracy: 0.8198\n","Epoch 2/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3883 - accuracy: 0.8286 - val_loss: 0.3844 - val_accuracy: 0.8242\n","Epoch 3/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3688 - accuracy: 0.8382 - val_loss: 0.3692 - val_accuracy: 0.8333\n","Epoch 4/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3541 - accuracy: 0.8436 - val_loss: 0.3798 - val_accuracy: 0.8257\n","Epoch 5/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3446 - accuracy: 0.8464 - val_loss: 0.3665 - val_accuracy: 0.8338\n","Epoch 6/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3353 - accuracy: 0.8520 - val_loss: 0.4104 - val_accuracy: 0.8247\n","Epoch 7/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3257 - accuracy: 0.8540 - val_loss: 0.3680 - val_accuracy: 0.8325\n","Epoch 8/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3188 - accuracy: 0.8594 - val_loss: 0.3659 - val_accuracy: 0.8334\n","Epoch 9/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3110 - accuracy: 0.8602 - val_loss: 0.3800 - val_accuracy: 0.8334\n","Epoch 10/10\n","391/391 [==============================] - 20s 52ms/step - loss: 0.3048 - accuracy: 0.8656 - val_loss: 0.3928 - val_accuracy: 0.8343\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe1944c4e10>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Keod5xXkEKnx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637382492651,"user_tz":-120,"elapsed":268564,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"82e1091f-1737-4975-8930-9a2c0773060e"},"source":["########################### Scenario 2 ###########################\n","##################################################################\n","\n","### Set random seed to ensure deterministic results ###\n","import os\n","seed_value = 1\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","def reset_random_seeds():\n","   tf.random.set_seed(seed_value)\n","   np.random.seed(seed_value)\n","   random.seed(seed_value)\n","\n","reset_random_seeds() # randomly set initial data\n","\n","max_features = 1000  # Only consider the top 1k words\n","maxlen = 100 # Only consider the first 100 words of each movie review\n","\n","### Model design with Embedding and LSTM layers ####\n","inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n","x = layers.Embedding(input_dim=1000,output_dim=128)(inputs) # Embed data in a 128-dimensional vector\n","x = layers.LSTM(units=128,return_sequences='true' )(x) # Add 1st layer of LSTM with 128 hidden states (aka units); set return_sequences=true.\n","x = layers.LSTM(units=128 )(x) # Add 2nd layer of LSTM with 128 hidden states (aka units)\n","outputs = layers.Dense(units=1, activation=\"sigmoid\")(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n","\n","### Clear cached model to refresh memory and build new model for training ###\n","keras.backend.clear_session() # Clear cached model\n","model = keras.Model(inputs, outputs) # Build new keras model\n","model.summary() # Print out model summary\n","\n","# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n","# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)\n","model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"]) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n","model.fit(x_train,y_train,epochs=10,batch_size=64,validation_data=(x_val,y_val)) # Train the compiled model with model.fit()"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, None, 128)         128000    \n","                                                                 \n"," lstm (LSTM)                 (None, None, 128)         131584    \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dense (Dense)               (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 391,297\n","Trainable params: 391,297\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 28s 62ms/step - loss: 0.4926 - accuracy: 0.7555 - val_loss: 0.4026 - val_accuracy: 0.8196\n","Epoch 2/10\n","391/391 [==============================] - 21s 54ms/step - loss: 0.4089 - accuracy: 0.8158 - val_loss: 0.3998 - val_accuracy: 0.8142\n","Epoch 3/10\n","391/391 [==============================] - 21s 55ms/step - loss: 0.3604 - accuracy: 0.8398 - val_loss: 0.3657 - val_accuracy: 0.8357\n","Epoch 4/10\n","391/391 [==============================] - 21s 55ms/step - loss: 0.3406 - accuracy: 0.8487 - val_loss: 0.3692 - val_accuracy: 0.8384\n","Epoch 5/10\n","391/391 [==============================] - 21s 55ms/step - loss: 0.3214 - accuracy: 0.8604 - val_loss: 0.3536 - val_accuracy: 0.8422\n","Epoch 6/10\n","391/391 [==============================] - 21s 55ms/step - loss: 0.3043 - accuracy: 0.8698 - val_loss: 0.3559 - val_accuracy: 0.8438\n","Epoch 7/10\n","391/391 [==============================] - 21s 54ms/step - loss: 0.2892 - accuracy: 0.8770 - val_loss: 0.3524 - val_accuracy: 0.8441\n","Epoch 8/10\n","391/391 [==============================] - 21s 54ms/step - loss: 0.2770 - accuracy: 0.8833 - val_loss: 0.3553 - val_accuracy: 0.8423\n","Epoch 9/10\n","391/391 [==============================] - 21s 55ms/step - loss: 0.2573 - accuracy: 0.8914 - val_loss: 0.3736 - val_accuracy: 0.8345\n","Epoch 10/10\n","391/391 [==============================] - 21s 55ms/step - loss: 0.2410 - accuracy: 0.9010 - val_loss: 0.3886 - val_accuracy: 0.8374\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe194309210>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"DdiZbuCQt_QC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637382917650,"user_tz":-120,"elapsed":410969,"user":{"displayName":"Youssef Barsoom","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4ocxsNoH0aJVyRVyLWESRt4SjPVWVxezBdEGwFA=s64","userId":"09664226010496143611"}},"outputId":"92035b69-bdab-4e97-e446-e938feed0265"},"source":["########################### Scenario 3 ###########################\n","##################################################################\n","\n","### Set random seed to ensure deterministic results ###\n","import os\n","seed_value = 1\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","def reset_random_seeds():\n","   tf.random.set_seed(seed_value)\n","   np.random.seed(seed_value)\n","   random.seed(seed_value)\n","\n","reset_random_seeds() # randomly set initial data\n","\n","max_features =1000   # Only consider the top 1k words\n","maxlen = 200 # Only consider the first 200 words of each movie review\n","\n","(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=max_features) # load IMDB data with specified num_words = 1000; testing set is set to validation set.\n","print(len(x_train), \"Training sequences\")\n","print(len(x_val), \"Validation sequences\")\n","x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen ) # Pad IMDB training data with specified maxlen=200\n","x_val = keras.preprocessing.sequence.pad_sequences(x_val,maxlen) # Pad IMDB validation data with specified maxlen=200\n","\n","x = layers.Embedding(input_dim=1000,output_dim=128)(inputs) # Embed data in a 128-dimensional vector\n","x = layers.LSTM(units=128,return_sequences='true' )(x) # Add 1st layer of LSTM with 128 hidden states (aka units); set return_sequences=true.\n","x = layers.LSTM(units=128 )(x) # Add 2nd layer of LSTM with 128 hidden states (aka units)\n","outputs = layers.Dense(units=1, activation=\"sigmoid\")(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n","\n","### Clear cached model to refresh memory and build new model for training ###\n","keras.backend.clear_session() # Clear cached model\n","model = keras.Model(inputs, outputs) # Build new keras model\n","model.summary() # Print out model summary\n","\n","# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n","# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)\n","model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"]) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n","model.fit(x_train,y_train,epochs=10,batch_size=64,validation_data=(x_val,y_val)) "],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["25000 Training sequences\n","25000 Validation sequences\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, None, 128)         128000    \n","                                                                 \n"," lstm (LSTM)                 (None, None, 128)         131584    \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dense (Dense)               (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 391,297\n","Trainable params: 391,297\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 44s 104ms/step - loss: 0.5883 - accuracy: 0.6866 - val_loss: 0.4264 - val_accuracy: 0.8090\n","Epoch 2/10\n","391/391 [==============================] - 39s 100ms/step - loss: 0.4295 - accuracy: 0.8108 - val_loss: 0.3702 - val_accuracy: 0.8366\n","Epoch 3/10\n","391/391 [==============================] - 40s 101ms/step - loss: 0.3889 - accuracy: 0.8297 - val_loss: 0.3536 - val_accuracy: 0.8419\n","Epoch 4/10\n","391/391 [==============================] - 39s 101ms/step - loss: 0.4009 - accuracy: 0.8262 - val_loss: 0.3485 - val_accuracy: 0.8541\n","Epoch 5/10\n","391/391 [==============================] - 39s 101ms/step - loss: 0.3262 - accuracy: 0.8620 - val_loss: 0.3224 - val_accuracy: 0.8585\n","Epoch 6/10\n","391/391 [==============================] - 39s 101ms/step - loss: 0.3117 - accuracy: 0.8680 - val_loss: 0.3495 - val_accuracy: 0.8515\n","Epoch 7/10\n","391/391 [==============================] - 39s 101ms/step - loss: 0.3065 - accuracy: 0.8709 - val_loss: 0.3224 - val_accuracy: 0.8550\n","Epoch 8/10\n","391/391 [==============================] - 40s 101ms/step - loss: 0.2939 - accuracy: 0.8785 - val_loss: 0.3173 - val_accuracy: 0.8640\n","Epoch 9/10\n","391/391 [==============================] - 39s 101ms/step - loss: 0.2767 - accuracy: 0.8860 - val_loss: 0.3069 - val_accuracy: 0.8687\n","Epoch 10/10\n","391/391 [==============================] - 39s 101ms/step - loss: 0.2670 - accuracy: 0.8899 - val_loss: 0.2988 - val_accuracy: 0.8706\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe19255f990>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"oRu2xHOIt_QE"},"source":[""],"execution_count":null,"outputs":[]}]}